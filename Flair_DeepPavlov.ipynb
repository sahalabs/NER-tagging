{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "New_algos.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahalabs/NER-tagging/blob/master/Flair_DeepPavlov.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2yJtdODsmI-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a51e63f-cf4a-44c6-e240-e58bc513015e"
      },
      "source": [
        "##Uploading file from google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nmGrfJcxIBf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1159
        },
        "outputId": "23df1510-a1e0-42f4-916c-41baebae3a02"
      },
      "source": [
        "!pip3 install flair ####Dependencies for Flair\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flair in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from flair) (2019.6.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.20 in /usr/local/lib/python3.6/dist-packages (from flair) (1.23)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.3)\n",
            "Requirement already satisfied: deprecated>=1.2.4 in /usr/local/lib/python3.6/dist-packages (from flair) (1.2.5)\n",
            "Requirement already satisfied: sqlitedict>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.6.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from flair) (0.0)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n",
            "Collecting tqdm>=4.26.0 (from flair)\n",
            "  Using cached https://files.pythonhosted.org/packages/45/af/685bf3ce889ea191f3b916557f5677cc95a5e87b2fa120d74b5dd6d049d0/tqdm-4.32.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pytest>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.4)\n",
            "Requirement already satisfied: bpemb>=0.2.9 in /usr/local/lib/python3.6/dist-packages (from flair) (0.3.0)\n",
            "Requirement already satisfied: mpld3==0.3 in /usr/local/lib/python3.6/dist-packages (from flair) (0.3)\n",
            "Requirement already satisfied: pytorch-pretrained-bert>=0.6.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.6.2)\n",
            "Requirement already satisfied: segtok>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from flair) (1.5.7)\n",
            "Collecting gensim>=3.4.0 (from flair)\n",
            "  Using cached https://files.pythonhosted.org/packages/d3/4b/19eecdf07d614665fa889857dc56ac965631c7bd816c3476d2f0cac6ea3b/gensim-3.7.3-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.1.0)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.0.3)\n",
            "Requirement already satisfied: wrapt<2,>=1 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.11.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->flair) (0.19.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.3)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (3.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.14.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.12.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (7.0.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (19.1.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.8.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (0.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (39.1.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from bpemb>=0.2.9->flair) (0.1.82)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from bpemb>=0.2.9->flair) (2.19.1)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert>=0.6.1->flair) (1.9.165)\n",
            "Requirement already satisfied: smart-open>=1.7.0 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.8.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.5.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.1.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair) (2019.3.9)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair) (3.0.4)\n",
            "Requirement already satisfied: idna<2.8,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb>=0.2.9->flair) (2.7)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.165 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert>=0.6.1->flair) (1.12.165)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.7.0->gensim>=3.4.0->flair) (2.49.0)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.165->boto3->pytorch-pretrained-bert>=0.6.1->flair) (0.14)\n",
            "\u001b[31mERROR: spacy 2.1.4 has requirement numpy>=1.15.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fastai 1.0.52 has requirement numpy>=1.15, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: deeppavlov 0.3.1 has requirement tqdm==4.23.4, but you'll have tqdm 4.32.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tqdm, gensim\n",
            "  Found existing installation: tqdm 4.23.4\n",
            "    Uninstalling tqdm-4.23.4:\n",
            "      Successfully uninstalled tqdm-4.23.4\n",
            "  Found existing installation: gensim 2.3.0\n",
            "    Uninstalling gensim-2.3.0:\n",
            "      Successfully uninstalled gensim-2.3.0\n",
            "Successfully installed gensim-3.7.3 tqdm-4.32.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gensim",
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XqTXu8mOILy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install deeppavlov ##Dependencies for deeppavlov\n",
        "!python3 -m deeppavlov install ner_ontonotes\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6ui7skTtNNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Importing file and converting to a pandas dataframe\n",
        "import pandas as pd\n",
        "path = r\"/content/drive/My Drive/Data/ult_test_file.csv\"\n",
        "df_bonus = pd.read_csv(path)\n",
        "# Dataset is now stored in a Pandas Dataframe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yN2gRdSoxQV4",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrjgTbAowzE4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "f5a77bf8-9fbe-4576-dc92-c69b09072d24"
      },
      "source": [
        "df_bonus.info() ##Uber level information about the DataFrame"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 14 entries, 0 to 13\n",
            "Data columns (total 5 columns):\n",
            "node_id          14 non-null int64\n",
            "language         14 non-null object\n",
            "node_fullbody    14 non-null object\n",
            "node_title       14 non-null object\n",
            "node_type        14 non-null object\n",
            "dtypes: int64(1), object(4)\n",
            "memory usage: 640.0+ bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJ2KY8JyvA-g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5579
        },
        "outputId": "574850c4-c5da-4a88-9235-07fd98187a2f"
      },
      "source": [
        "##Implementing DeepPavlov and Flair NER models on each article\n",
        "from deeppavlov import configs, build_model\n",
        "\n",
        "df_bonus['deeppavlov'] = ''\n",
        "df_bonus['flair'] = ''\n",
        "\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "for index,row in df_bonus.iterrows():\n",
        "  \n",
        "  text = row['node_fullbody']\n",
        "  deeppavlov_ner = build_model(configs.ner.ner_ontonotes, download=True)\n",
        "  s2 = deeppavlov_ner([text])\n",
        "  ##########\n",
        "  temp_word_list = []\n",
        "  final_list = []\n",
        "  temp_tag_list = []\n",
        "  for x in range(0,len(s2[0][0])):\n",
        "\n",
        "    if(s2[1][0][x][0] == 'B'):\n",
        "      count = 1\n",
        "      temp_tag_list.append(s2[1][0][x].strip('B-'))\n",
        "      temp_word_list.append(s2[0][0][x])\n",
        "\n",
        "    elif(s2[1][0][x][0] == 'I'):\n",
        "      count +=1\n",
        "      temp_word_list.append(s2[0][0][x])\n",
        "    elif(s2[1][0][x][0] == 'O'):\n",
        "      if(count == 1):\n",
        "        final_list.append((temp_word_list[0],temp_tag_list[0]))\n",
        "        temp_word_list = []\n",
        "        temp_tag_list = []\n",
        "        count = 0\n",
        "      elif(count > 1):\n",
        "        final_list.append((' '.join(temp_word_list),temp_tag_list[0]))\n",
        "        count = 0\n",
        "        temp_word_list = []\n",
        "        temp_tag_list = []\n",
        "      else:\n",
        "        a=9\n",
        "\n",
        "    else:\n",
        "      a=9\n",
        "    df_bonus.at[index,'deeppavlov'] = final_list\n",
        "  \n",
        "  print(\"Finished index:\"+str(index))\n",
        "\n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:21:24.874 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz download because of matching hashes\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:21:24,874 Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz download because of matching hashes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:21:25.793 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt download because of matching hashes\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:21:25,793 Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt download because of matching hashes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:21:26.10 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/tag.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:21:26,010 [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/tag.dict]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:21:26.13 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/char.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:21:26,013 [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/char.dict]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:21:26.18 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:21:26,018 [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "2019-06-14 04:21:55.576 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:21:55,576 \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:21:55.674 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:21:55,674 \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "2019-06-14 04:21:57.717 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [loading model from /root/.deeppavlov/models/ner_ontonotes/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:21:57,717 [loading model from /root/.deeppavlov/models/ner_ontonotes/model]\n",
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_ontonotes/model\n",
            "2019-06-14 04:21:57,747 Restoring parameters from /root/.deeppavlov/models/ner_ontonotes/model\n",
            "Finished index:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:21:59.110 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz download because of matching hashes\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:21:59,110 Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz download because of matching hashes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:22:00.36 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt download because of matching hashes\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:22:00,036 Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt download because of matching hashes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:22:00.243 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/tag.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:22:00,243 [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/tag.dict]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:22:00.248 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/char.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:22:00,248 [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/char.dict]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:22:00.254 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:22:00,254 [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:22:29.737 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:22:29,737 \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:22:29.845 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:22:29,845 \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:22:31.525 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [loading model from /root/.deeppavlov/models/ner_ontonotes/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:22:31,525 [loading model from /root/.deeppavlov/models/ner_ontonotes/model]\n",
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_ontonotes/model\n",
            "2019-06-14 04:22:31,553 Restoring parameters from /root/.deeppavlov/models/ner_ontonotes/model\n",
            "Finished index:1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:22:34.406 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz download because of matching hashes\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:22:34,406 Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz download because of matching hashes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:22:35.319 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt download because of matching hashes\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:22:35,319 Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt download because of matching hashes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:22:35.523 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/tag.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:22:35,523 [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/tag.dict]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:22:35.529 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/char.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:22:35,529 [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/char.dict]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:22:35.533 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:22:35,533 [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:04.533 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:04,533 \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:04.630 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:04,630 \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:06.290 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [loading model from /root/.deeppavlov/models/ner_ontonotes/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:06,290 [loading model from /root/.deeppavlov/models/ner_ontonotes/model]\n",
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_ontonotes/model\n",
            "2019-06-14 04:23:06,320 Restoring parameters from /root/.deeppavlov/models/ner_ontonotes/model\n",
            "Finished index:2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:06.925 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz download because of matching hashes\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:06,925 Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz download because of matching hashes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:07.831 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt download because of matching hashes\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:07,831 Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt download because of matching hashes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:08.41 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/tag.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:08,041 [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/tag.dict]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:08.47 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/char.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:08,047 [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/char.dict]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:08.53 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:08,053 [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:38.72 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:38,072 \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:38.169 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:38,169 \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:39.860 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [loading model from /root/.deeppavlov/models/ner_ontonotes/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:39,860 [loading model from /root/.deeppavlov/models/ner_ontonotes/model]\n",
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_ontonotes/model\n",
            "2019-06-14 04:23:39,889 Restoring parameters from /root/.deeppavlov/models/ner_ontonotes/model\n",
            "Finished index:3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:40.899 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz download because of matching hashes\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:40,899 Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz download because of matching hashes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:41.812 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt download because of matching hashes\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:41,812 Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt download because of matching hashes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:42.32 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/tag.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:42,032 [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/tag.dict]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:42.34 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/char.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:42,034 [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/char.dict]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:42.39 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:23:42,039 [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:11.470 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:11,470 \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:11.566 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:11,566 \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:13.224 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [loading model from /root/.deeppavlov/models/ner_ontonotes/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:13,224 [loading model from /root/.deeppavlov/models/ner_ontonotes/model]\n",
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_ontonotes/model\n",
            "2019-06-14 04:24:13,252 Restoring parameters from /root/.deeppavlov/models/ner_ontonotes/model\n",
            "Finished index:4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:13.857 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz download because of matching hashes\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:13,857 Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz download because of matching hashes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:14.777 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt download because of matching hashes\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:14,777 Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt download because of matching hashes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:14.978 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/tag.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:14,978 [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/tag.dict]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:14.983 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/char.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:14,983 [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/char.dict]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:14.986 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:14,986 [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:44.288 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:44,288 \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:44.386 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:44,386 \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:46.551 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [loading model from /root/.deeppavlov/models/ner_ontonotes/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:46,551 [loading model from /root/.deeppavlov/models/ner_ontonotes/model]\n",
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_ontonotes/model\n",
            "2019-06-14 04:24:46,581 Restoring parameters from /root/.deeppavlov/models/ner_ontonotes/model\n",
            "Finished index:5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:47.705 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz download because of matching hashes\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:47,705 Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz download because of matching hashes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:48.620 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt download because of matching hashes\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:48,620 Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt download because of matching hashes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:48.825 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/tag.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:48,825 [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/tag.dict]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:48.830 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/char.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:48,830 [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/char.dict]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:48.833 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:24:48,833 [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:17.496 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:17,496 \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:18.109 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:18,109 \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:19.767 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [loading model from /root/.deeppavlov/models/ner_ontonotes/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:19,767 [loading model from /root/.deeppavlov/models/ner_ontonotes/model]\n",
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_ontonotes/model\n",
            "2019-06-14 04:25:19,795 Restoring parameters from /root/.deeppavlov/models/ner_ontonotes/model\n",
            "Finished index:6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:21.138 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz download because of matching hashes\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:21,138 Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz download because of matching hashes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:22.42 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt download because of matching hashes\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:22,042 Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt download because of matching hashes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:22.241 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/tag.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:22,241 [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/tag.dict]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:22.247 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/char.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:22,247 [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/char.dict]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:22.251 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:22,251 [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:51.299 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:51,299 \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:51.396 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:51,396 \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:53.82 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [loading model from /root/.deeppavlov/models/ner_ontonotes/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:53,082 [loading model from /root/.deeppavlov/models/ner_ontonotes/model]\n",
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_ontonotes/model\n",
            "2019-06-14 04:25:53,112 Restoring parameters from /root/.deeppavlov/models/ner_ontonotes/model\n",
            "Finished index:7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:55.60 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz download because of matching hashes\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:55,060 Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz download because of matching hashes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:55.976 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt download because of matching hashes\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:55,976 Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt download because of matching hashes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:56.170 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/tag.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:56,170 [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/tag.dict]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:56.177 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/char.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:56,177 [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/char.dict]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:56.183 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:25:56,183 [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:26:25.544 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:26:25,544 \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:26:25.640 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:26:25,640 \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:26:27.310 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [loading model from /root/.deeppavlov/models/ner_ontonotes/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:26:27,310 [loading model from /root/.deeppavlov/models/ner_ontonotes/model]\n",
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_ontonotes/model\n",
            "2019-06-14 04:26:27,338 Restoring parameters from /root/.deeppavlov/models/ner_ontonotes/model\n",
            "Finished index:8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:26:27.890 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz download because of matching hashes\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:26:27,890 Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz download because of matching hashes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:26:28.805 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt download because of matching hashes\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:26:28,805 Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt download because of matching hashes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:26:29.13 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/tag.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:26:29,013 [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/tag.dict]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:26:29.15 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/char.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:26:29,015 [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/char.dict]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:26:29.20 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:26:29,020 [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:26:58.528 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:26:58,528 \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:26:58.626 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:26:58,626 \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:27:00.341 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [loading model from /root/.deeppavlov/models/ner_ontonotes/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:27:00,341 [loading model from /root/.deeppavlov/models/ner_ontonotes/model]\n",
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_ontonotes/model\n",
            "2019-06-14 04:27:00,368 Restoring parameters from /root/.deeppavlov/models/ner_ontonotes/model\n",
            "Finished index:9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:27:00.925 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz download because of matching hashes\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:27:00,925 Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz download because of matching hashes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:27:01.830 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt download because of matching hashes\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:27:01,830 Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt download because of matching hashes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:27:02.30 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/tag.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:27:02,030 [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/tag.dict]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:27:02.35 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/char.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:27:02,035 [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/char.dict]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:27:02.41 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:27:02,041 [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:27:31.534 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:27:31,534 \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:27:31.634 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:27:31,634 \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:27:33.351 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [loading model from /root/.deeppavlov/models/ner_ontonotes/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:27:33,351 [loading model from /root/.deeppavlov/models/ner_ontonotes/model]\n",
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_ontonotes/model\n",
            "2019-06-14 04:27:33,380 Restoring parameters from /root/.deeppavlov/models/ner_ontonotes/model\n",
            "Finished index:10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:27:33.942 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz download because of matching hashes\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:27:33,942 Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz download because of matching hashes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:27:34.849 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt download because of matching hashes\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:27:34,849 Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt download because of matching hashes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:27:35.45 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/tag.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:27:35,045 [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/tag.dict]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:27:35.48 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/char.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:27:35,048 [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/char.dict]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:27:35.55 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:27:35,055 [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:04.254 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:04,254 \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:04.349 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:04,349 \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:06.38 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [loading model from /root/.deeppavlov/models/ner_ontonotes/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:06,038 [loading model from /root/.deeppavlov/models/ner_ontonotes/model]\n",
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_ontonotes/model\n",
            "2019-06-14 04:28:06,067 Restoring parameters from /root/.deeppavlov/models/ner_ontonotes/model\n",
            "Finished index:11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:06.621 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz download because of matching hashes\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:06,621 Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz download because of matching hashes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:07.527 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt download because of matching hashes\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:07,527 Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt download because of matching hashes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:07.730 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/tag.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:07,730 [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/tag.dict]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:07.732 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/char.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:07,732 [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/char.dict]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:07.735 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:07,735 [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:37.319 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:37,319 \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:37.417 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:37,417 \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:39.113 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [loading model from /root/.deeppavlov/models/ner_ontonotes/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:39,113 [loading model from /root/.deeppavlov/models/ner_ontonotes/model]\n",
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_ontonotes/model\n",
            "2019-06-14 04:28:39,143 Restoring parameters from /root/.deeppavlov/models/ner_ontonotes/model\n",
            "Finished index:12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:39.734 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz download because of matching hashes\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:39,734 Skipped http://files.deeppavlov.ai/deeppavlov_data/ner_ontonotes_v3_cpu_compatible.tar.gz download because of matching hashes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:40.657 INFO in 'deeppavlov.download'['download'] at line 116: Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt download because of matching hashes\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:40,657 Skipped http://files.deeppavlov.ai/embeddings/glove.6B.100d.txt download because of matching hashes\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:40.857 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/tag.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:40,857 [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/tag.dict]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:40.861 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 103: [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/char.dict]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:40,861 [loading vocabulary from /root/.deeppavlov/models/ner_ontonotes/char.dict]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:40.864 INFO in 'deeppavlov.models.embedders.glove_embedder'['glove_embedder'] at line 52: [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:28:40,864 [loading GloVe embeddings from `/root/.deeppavlov/downloads/embeddings/glove.6B.100d.txt`]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:29:10.398 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:29:10,398 \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:29:10.498 INFO in 'deeppavlov.core.layers.tf_layers'['tf_layers'] at line 756: \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:29:10,498 \n",
            "Warning! tf.contrib.cudnn_rnn.CudnnCompatibleLSTMCell is used. It is okay for inference mode, but if you train your model with this cell it could NOT be used with tf.contrib.cudnn_rnn.CudnnLSTMCell later. \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:29:12.245 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 52: [loading model from /root/.deeppavlov/models/ner_ontonotes/model]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:29:12,245 [loading model from /root/.deeppavlov/models/ner_ontonotes/model]\n",
            "INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_ontonotes/model\n",
            "2019-06-14 04:29:12,276 Restoring parameters from /root/.deeppavlov/models/ner_ontonotes/model\n",
            "Finished index:13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbZ87ePjN17v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "cb0704e6-6788-4aef-ab51-b213d48c3494"
      },
      "source": [
        "from flair.models import SequenceTagger\n",
        "df_bonus['flair'] = ''\n",
        "for index,row in df_bonus.iterrows():\n",
        "  ############\n",
        "  #######flairrr\n",
        "  final_list = []\n",
        "  text = row['node_fullbody']\n",
        "  model = SequenceTagger.load('ner-ontonotes-fast') #.load('ner')\n",
        "  from flair.data import Sentence\n",
        "  s = Sentence(text)\n",
        "  model.predict(s)\n",
        "  z2 = s.to_dict(tag_type='ner')\n",
        "  for x in z2['entities']:\n",
        "    final_list.append((x['text'],x['type']))\n",
        "  df_bonus.at[index,'flair'] = final_list"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-06-14 04:45:48,136 loading file /root/.flair/models/en-ner-ontonotes-fast-v0.3.pt\n",
            "2019-06-14 04:45:59,921 loading file /root/.flair/models/en-ner-ontonotes-fast-v0.3.pt\n",
            "2019-06-14 04:46:11,641 loading file /root/.flair/models/en-ner-ontonotes-fast-v0.3.pt\n",
            "2019-06-14 04:46:15,699 loading file /root/.flair/models/en-ner-ontonotes-fast-v0.3.pt\n",
            "2019-06-14 04:46:20,955 loading file /root/.flair/models/en-ner-ontonotes-fast-v0.3.pt\n",
            "2019-06-14 04:46:25,072 loading file /root/.flair/models/en-ner-ontonotes-fast-v0.3.pt\n",
            "2019-06-14 04:46:31,097 loading file /root/.flair/models/en-ner-ontonotes-fast-v0.3.pt\n",
            "2019-06-14 04:46:37,531 loading file /root/.flair/models/en-ner-ontonotes-fast-v0.3.pt\n",
            "2019-06-14 04:46:46,193 loading file /root/.flair/models/en-ner-ontonotes-fast-v0.3.pt\n",
            "2019-06-14 04:46:49,839 loading file /root/.flair/models/en-ner-ontonotes-fast-v0.3.pt\n",
            "2019-06-14 04:46:53,509 loading file /root/.flair/models/en-ner-ontonotes-fast-v0.3.pt\n",
            "2019-06-14 04:46:57,461 loading file /root/.flair/models/en-ner-ontonotes-fast-v0.3.pt\n",
            "2019-06-14 04:47:01,515 loading file /root/.flair/models/en-ner-ontonotes-fast-v0.3.pt\n",
            "2019-06-14 04:47:05,353 loading file /root/.flair/models/en-ner-ontonotes-fast-v0.3.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQW1VXHpTyTz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "9e075037-2124-4503-acc1-cdda13ad32da"
      },
      "source": [
        "df_bonus['flair']"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     [(Eid ul Fitr,, PERSON), (Muslims, NORP), (the...\n",
              "1     [(Rajesh Kumar, PERSON), (14Works, ORG), (Maur...\n",
              "2     [(India,, GPE), (Indian, NORP), (Western, NORP...\n",
              "3     [(P.J Cherian:, PERSON), (Pattanam, PERSON), (...\n",
              "4     [(the Central Board of Secondary Education, OR...\n",
              "5     [(G. Sundari:, PERSON), (the Kalakshetra Found...\n",
              "6     [(APPACHA KAVI, PERSON), (Ramakrishna, Kushaln...\n",
              "7     [(KrishnaIntroduction Rs,, PERSON), (Navratri...\n",
              "8     [(Two, CARDINAL), (September 1, DATE), (Octobe...\n",
              "9     [(the late 1980s,, DATE), (Thiruvananthapuram,...\n",
              "10    [(Bengali, LANGUAGE), (Hindi, Mar, ORG), (Assa...\n",
              "11    [(Sufi, NORP), (Hazrat Imam Nasiruddin Abu Yus...\n",
              "12    [(;Kaaralsman Charitham/A, PERSON), (Charlemag...\n",
              "13    [(Gondi Vivah Geet;, PERSON), (Kachargarh, GPE...\n",
              "Name: flair, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUdJpiJw4lrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_bonus.to_csv(\"Flair_Results.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_gUSKcWQXBp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('Flair_Results.csv') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WioWtcB0R9Hx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b1d68190-5f20-451e-ded0-ff68ad340ee8"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/Data/'  #change dir to your project folder"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83SOhFiISYPr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "973105ce-b682-47ac-8f1f-96b4a8502261"
      },
      "source": [
        "!mkdir -p ~/.pavlov\n",
        "!cp DeepPavlov_Results.csv ~/.pavlov/\n",
        "!ls ~/.pavlov\n",
        "!chmod 600 /root/.pavlov/DeepPavlov_Results.csv  # set permission"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DeepPavlov_Results.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpPeiyr3J1ew",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "7f1ba591-d4a7-4422-916a-9d1ade816911"
      },
      "source": [
        "!cp DeepPavlov_Results.csv  /content/drive/"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cp: cannot create regular file '/content/drive/DeepPavlov_Results.csv': Operation not supported\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}