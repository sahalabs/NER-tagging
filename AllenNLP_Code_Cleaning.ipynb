{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AllenNLP_Code_Cleaning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sahalabs/NER-tagging/blob/master/AllenNLP_Code_Cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVA3pAxCI-9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/allenai/allennlp\n",
        "\n",
        "!pip install allennlp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pRisV_6JBAP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Run this algorithm\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Wed May 22 18:48:17 2019\n",
        "\n",
        "@author: Vivek\n",
        "\"\"\"\n",
        "\n",
        "### using neuroner\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "# from neuroner import neuromodel\n",
        "\n",
        "text = 'The Adivasi Academy, Tejgadh, in Chhota Udepur district (Gujarat) was established in 1999 by Bhasha Research Publication Centre, Vadodara (Bhasha), with the vision of it evolving into an institute of national significance to undertake the study, research and documentation of the Adivasi communities of India. The Academy acts as a think-tank and functions as a one-stop resource centre for the study of multifarious aspects of the kaleidoscopic worlds of Adivasi communities, ranging from history, mythology, folklore, anthropology, ethnography, demographics, art, music, culture, geography, medicine, economy and languages. The Academy is administered and managed by Adivasi community members trained through various educational and vocational activities. The Adivasi Academy houses the Vaacha museum, a research library, Lakhara art studio, Bhasha Van — an open-air museum of languages, Vasant Shala — a residential multilingual school for Adivasi children, and Prakruti health clinic. The Academy has executed several national-scale initiatives in linguistics, ethnography, Adivasi art and Adivasi music.'\n",
        "\n",
        "### using allennlp\n",
        "from allennlp.predictors.predictor import Predictor\n",
        "predictor = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/ner-model-2018.12.18.tar.gz\")\n",
        "z1 = predictor.predict(sentence = text)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUM3a3h2JDTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "####Block which cleans the code and concatenates into one single list\n",
        "temp_word_list = []\n",
        "temp_tag_list = []\n",
        "final_list = []\n",
        "count = 0\n",
        "for x in range(0,len(z1['words'])):\n",
        "\n",
        "    if(z1['tags'][x][0] == 'B'):\n",
        "      count = 1\n",
        "      temp_tag_list.append(z1['tags'][x].strip('B-'))\n",
        "      temp_word_list.append(z1['words'][x])\n",
        "\n",
        "    elif(z1['tags'][x][0] == 'I'):\n",
        "      count +=1\n",
        "      temp_word_list.append(z1['words'][x])\n",
        "    elif(z1['tags'][x][0] == 'L'):\n",
        "      count +=1\n",
        "      temp_word_list.append(z1['words'][x])\n",
        "    elif(z1['tags'][x][0] == 'U'):\n",
        "      count=1\n",
        "      temp_tag_list.append(z1['tags'][x].strip('U-'))\n",
        "      temp_word_list.append(z1['words'][x])\n",
        "    elif(z1['tags'][x][0] == 'O'):\n",
        "      if(count == 1):\n",
        "        final_list.append((temp_word_list[0],temp_tag_list[0]))\n",
        "        temp_word_list = []\n",
        "        temp_tag_list = []\n",
        "        count = 0\n",
        "      elif(count > 1):\n",
        "        final_list.append((' '.join(temp_word_list),temp_tag_list[0]))\n",
        "        count = 0\n",
        "        temp_word_list = []\n",
        "        temp_tag_list = []\n",
        "      else:\n",
        "        a=9\n",
        "\n",
        "    else:\n",
        "      a=9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krn3lLQIJFTZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFSJZVpbJH3b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fine grained and elmo combined model\n",
        "from allennlp.predictors.predictor import Predictor\n",
        "import pandas as pd\n",
        "\n",
        "predictor = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/fine-grained-ner-model-elmo-2018.12.21.tar.gz\")\n",
        "z2 = predictor.predict(sentence = text)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbCQK6vQJLFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp_word_list = []\n",
        "temp_tag_list = []\n",
        "final_list = []\n",
        "count = 0\n",
        "for x in range(0,len(z2['words'])):\n",
        "\n",
        "    if(z2['tags'][x][0] == 'B'):\n",
        "      count = 1\n",
        "      temp_tag_list.append(z2['tags'][x].strip('B-'))\n",
        "      temp_word_list.append(z2['words'][x])\n",
        "\n",
        "    elif(z2['tags'][x][0] == 'I'):\n",
        "      count +=1\n",
        "      temp_word_list.append(z2['words'][x])\n",
        "    elif(z2['tags'][x][0] == 'L'):\n",
        "      count +=1\n",
        "      temp_word_list.append(z2['words'][x])\n",
        "    elif(z2['tags'][x][0] == 'U'):\n",
        "      count=1\n",
        "      temp_tag_list.append(z2['tags'][x].strip('U-'))\n",
        "      temp_word_list.append(z2['words'][x])\n",
        "    elif(z2['tags'][x][0] == 'O'):\n",
        "      if(count == 1):\n",
        "        final_list.append((temp_word_list[0],temp_tag_list[0]))\n",
        "        temp_word_list = []\n",
        "        temp_tag_list = []\n",
        "        count = 0\n",
        "      elif(count > 1):\n",
        "        final_list.append((' '.join(temp_word_list),temp_tag_list[0]))\n",
        "        count = 0\n",
        "        temp_word_list = []\n",
        "        temp_tag_list = []\n",
        "      else:\n",
        "        a=9\n",
        "\n",
        "    else:\n",
        "      a=9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HSBNjqjJRNj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###\n",
        "df_bonus = ##Read your csv file here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL_jQv1gJZaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from allennlp.predictors.predictor import Predictor\n",
        "df_bonus['allenNLP'] = ''\n",
        "import pandas as pd\n",
        "for index,row in df_bonus.iterrows():\n",
        " \n",
        "  predictor = Predictor.from_path(\"https://s3-us-west-2.amazonaws.com/allennlp/models/fine-grained-ner-model-elmo-2018.12.21.tar.gz\")\n",
        "  z2 = predictor.predict(sentence = row['node_fullbody'])\n",
        "  \n",
        "  ####\n",
        "  temp_word_list = []\n",
        "  temp_tag_list = []\n",
        "  final_list = []\n",
        "  count = 0\n",
        "  for x in range(0,len(z2['words'])):\n",
        "\n",
        "      if(z2['tags'][x][0] == 'B'):\n",
        "        count = 1\n",
        "        temp_tag_list.append(z2['tags'][x].strip('B-'))\n",
        "        temp_word_list.append(z2['words'][x])\n",
        "\n",
        "      elif(z2['tags'][x][0] == 'I'):\n",
        "        count +=1\n",
        "        temp_word_list.append(z2['words'][x])\n",
        "      elif(z2['tags'][x][0] == 'L'):\n",
        "        count +=1\n",
        "        temp_word_list.append(z2['words'][x])\n",
        "      elif(z2['tags'][x][0] == 'U'):\n",
        "        count=1\n",
        "        temp_tag_list.append(z2['tags'][x].strip('U-'))\n",
        "        temp_word_list.append(z2['words'][x])\n",
        "      elif(z2['tags'][x][0] == 'O'):\n",
        "        if(count == 1):\n",
        "          final_list.append((temp_word_list[0],temp_tag_list[0]))\n",
        "          temp_word_list = []\n",
        "          temp_tag_list = []\n",
        "          count = 0\n",
        "        elif(count > 1):\n",
        "          final_list.append((' '.join(temp_word_list),temp_tag_list[0]))\n",
        "          count = 0\n",
        "          temp_word_list = []\n",
        "          temp_tag_list = []\n",
        "        else:\n",
        "          a=9\n",
        "\n",
        "      else:\n",
        "        a=9\n",
        "  df_bonus.at[index,'allenNLP'] = final_list\n",
        " \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}